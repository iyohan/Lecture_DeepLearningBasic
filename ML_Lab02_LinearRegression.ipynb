{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis and cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H(x) = Wx + b  \n",
    "cost(W, b) = 1/m * sig(i=1, m)(H(x_i) - y_i^2)  \n",
    "  \n",
    "학습이란? cost function을 minimize하는 것!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build graph using TF operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H(x) = Wx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis Wx + b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 Variable은 일반적인 변수와는 다르다.  \n",
    "텐서플로가 학습하면서 바꾸는 변수로, **trainable variable**이라고도 불린다.  \n",
    "  \n",
    "값을 모르기 때문에, 먼저 랜덤으로 생성하고, shape을 [1]로 해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cost(W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce_mean()은 어떤 텐서가 있을 때, 그것의 평균을 구해준다.  \n",
    "  \n",
    "t = [1., 2., 3., 4.]  \n",
    "tf.reduce_mean(t) ==> 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5\n"
     ]
    }
   ],
   "source": [
    "# reduce_mean의 예.\n",
    "t = [1., 2., 3., 4.]\n",
    "test = tf.Session()\n",
    "print(test.run(tf.reduce_mean(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)  # cost minimize 하는 node(이름: train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run/update graph and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0343137 [-0.2310593] [0.45613366]\n",
      "20 0.13577645 [0.56735367] [0.76046973]\n",
      "40 0.08309016 [0.6582018] [0.7557501]\n",
      "60 0.07509915 [0.6809795] [0.7231864]\n",
      "80 0.06820291 [0.6966116] [0.6894805]\n",
      "100 0.061942935 [0.71093065] [0.65710425]\n",
      "120 0.056257594 [0.7245216] [0.6262254]\n",
      "140 0.051094055 [0.7374686] [0.59679544]\n",
      "160 0.04640447 [0.7498066] [0.5687483]\n",
      "180 0.042145286 [0.7615648] [0.54201925]\n",
      "200 0.03827702 [0.7727704] [0.51654637]\n",
      "220 0.0347638 [0.78344935] [0.49227053]\n",
      "240 0.031573024 [0.7936264] [0.4691356]\n",
      "260 0.028675111 [0.80332524] [0.44708797]\n",
      "280 0.026043212 [0.81256825] [0.42607647]\n",
      "300 0.023652857 [0.8213768] [0.40605247]\n",
      "320 0.02148191 [0.8297715] [0.3869695]\n",
      "340 0.0195102 [0.83777153] [0.36878338]\n",
      "360 0.017719494 [0.8453957] [0.35145196]\n",
      "380 0.01609315 [0.8526615] [0.334935]\n",
      "400 0.014616046 [0.8595858] [0.31919435]\n",
      "420 0.01327452 [0.8661848] [0.30419344]\n",
      "440 0.01205615 [0.87247366] [0.2898975]\n",
      "460 0.010949586 [0.87846684] [0.27627334]\n",
      "480 0.009944584 [0.8841785] [0.26328945]\n",
      "500 0.009031833 [0.8896217] [0.25091583]\n",
      "520 0.008202844 [0.89480907] [0.23912373]\n",
      "540 0.0074499473 [0.89975274] [0.22788577]\n",
      "560 0.006766165 [0.9044639] [0.21717596]\n",
      "580 0.0061451388 [0.9089538] [0.20696948]\n",
      "600 0.005581111 [0.9132326] [0.19724266]\n",
      "620 0.0050688544 [0.9173103] [0.18797302]\n",
      "640 0.0046036267 [0.9211964] [0.17913902]\n",
      "660 0.004181094 [0.92489994] [0.17072016]\n",
      "680 0.0037973325 [0.9284293] [0.16269696]\n",
      "700 0.0034488002 [0.9317929] [0.15505077]\n",
      "720 0.0031322467 [0.93499845] [0.1477639]\n",
      "740 0.002844752 [0.9380532] [0.14081953]\n",
      "760 0.0025836478 [0.9409645] [0.13420153]\n",
      "780 0.0023465126 [0.943739] [0.12789457]\n",
      "800 0.002131142 [0.94638306] [0.12188397]\n",
      "820 0.0019355394 [0.9489029] [0.11615588]\n",
      "840 0.0017578829 [0.95130426] [0.11069695]\n",
      "860 0.0015965427 [0.9535927] [0.10549458]\n",
      "880 0.0014500035 [0.9557737] [0.10053673]\n",
      "900 0.0013169158 [0.9578521] [0.0958119]\n",
      "920 0.0011960474 [0.9598331] [0.0913091]\n",
      "940 0.001086268 [0.9617207] [0.08701786]\n",
      "960 0.0009865599 [0.9635197] [0.08292834]\n",
      "980 0.0008960147 [0.9652341] [0.079031]\n",
      "1000 0.0008137715 [0.966868] [0.07531683]\n",
      "1020 0.00073908083 [0.9684251] [0.07177722]\n",
      "1040 0.0006712495 [0.96990895] [0.06840403]\n",
      "1060 0.0006096343 [0.97132313] [0.06518927]\n",
      "1080 0.00055368064 [0.97267085] [0.06212561]\n",
      "1100 0.0005028616 [0.9739552] [0.05920593]\n",
      "1120 0.00045671043 [0.9751792] [0.05642349]\n",
      "1140 0.00041479166 [0.9763457] [0.05377179]\n",
      "1160 0.00037672036 [0.9774574] [0.0512447]\n",
      "1180 0.0003421407 [0.9785168] [0.04883637]\n",
      "1200 0.00031073796 [0.9795265] [0.04654125]\n",
      "1220 0.00028221638 [0.9804887] [0.04435392]\n",
      "1240 0.00025631534 [0.9814056] [0.04226943]\n",
      "1260 0.00023278804 [0.9822795] [0.04028291]\n",
      "1280 0.00021142303 [0.9831123] [0.03838976]\n",
      "1300 0.00019201824 [0.983906] [0.03658558]\n",
      "1320 0.00017439241 [0.98466235] [0.03486615]\n",
      "1340 0.00015838548 [0.98538315] [0.03322754]\n",
      "1360 0.00014384829 [0.9860701] [0.03166596]\n",
      "1380 0.000130645 [0.9867248] [0.03017778]\n",
      "1400 0.00011865442 [0.9873486] [0.02875955]\n",
      "1420 0.000107764565 [0.9879432] [0.02740797]\n",
      "1440 9.787263e-05 [0.9885098] [0.02611992]\n",
      "1460 8.889133e-05 [0.9890498] [0.0248924]\n",
      "1480 8.073278e-05 [0.9895643] [0.02372261]\n",
      "1500 7.332117e-05 [0.99005485] [0.02260774]\n",
      "1520 6.6593035e-05 [0.99052227] [0.02154525]\n",
      "1540 6.0480947e-05 [0.99096763] [0.0205327]\n",
      "1560 5.492779e-05 [0.9913922] [0.01956772]\n",
      "1580 4.988699e-05 [0.9917967] [0.01864811]\n",
      "1600 4.5309145e-05 [0.9921822] [0.01777172]\n",
      "1620 4.1149557e-05 [0.9925496] [0.01693652]\n",
      "1640 3.737285e-05 [0.9928997] [0.01614055]\n",
      "1660 3.3942764e-05 [0.99323344] [0.01538201]\n",
      "1680 3.0827156e-05 [0.99355143] [0.0146591]\n",
      "1700 2.799758e-05 [0.9938545] [0.01397016]\n",
      "1720 2.5427957e-05 [0.9941433] [0.01331362]\n",
      "1740 2.3094466e-05 [0.9944185] [0.01268796]\n",
      "1760 2.0974387e-05 [0.9946809] [0.01209168]\n",
      "1780 1.9049136e-05 [0.9949308] [0.01152343]\n",
      "1800 1.7301276e-05 [0.9951691] [0.01098187]\n",
      "1820 1.5712807e-05 [0.99539614] [0.01046575]\n",
      "1840 1.4271169e-05 [0.9956125] [0.00997387]\n",
      "1860 1.2960874e-05 [0.9958187] [0.00950513]\n",
      "1880 1.17711825e-05 [0.9960152] [0.00905842]\n",
      "1900 1.0690771e-05 [0.99620247] [0.00863271]\n",
      "1920 9.709268e-06 [0.9963809] [0.008227]\n",
      "1940 8.818378e-06 [0.996551] [0.00784036]\n",
      "1960 8.0092095e-06 [0.9967131] [0.00747191]\n",
      "1980 7.27397e-06 [0.9968676] [0.00712074]\n",
      "2000 6.606009e-06 [0.9970148] [0.00678609]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph 필수!!\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)  # train이라는 node를 실행.\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placeholder를 이용해서 train을 할 때 그때 넘겨줄 수 있다.  \n",
    "먼저 학습 모델을 만들고, 필요할때 feed할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.012432083 [0.92130417] [1.3428706]\n",
      "20 0.009604593 [0.9363257] [1.329698]\n",
      "40 0.008387732 [0.9405404] [1.3146672]\n",
      "60 0.0073250644 [0.9444347] [1.3006083]\n",
      "80 0.006397015 [0.94807374] [1.2874702]\n",
      "100 0.0055865683 [0.9514744] [1.2751926]\n",
      "120 0.0048787654 [0.9546525] [1.2637188]\n",
      "140 0.004260663 [0.9576223] [1.2529968]\n",
      "160 0.003720882 [0.96039766] [1.242977]\n",
      "180 0.0032494955 [0.9629912] [1.2336135]\n",
      "200 0.0028378062 [0.9654149] [1.2248632]\n",
      "220 0.002478282 [0.9676799] [1.2166858]\n",
      "240 0.002164308 [0.9697966] [1.209044]\n",
      "260 0.0018900966 [0.97177464] [1.2019025]\n",
      "280 0.0016506404 [0.9736231] [1.1952289]\n",
      "300 0.001441516 [0.9753506] [1.1889921]\n",
      "320 0.0012588768 [0.97696483] [1.183164]\n",
      "340 0.001099394 [0.9784735] [1.1777174]\n",
      "360 0.0009601063 [0.9798833] [1.1726276]\n",
      "380 0.00083846494 [0.98120075] [1.1678711]\n",
      "400 0.0007322418 [0.9824319] [1.1634263]\n",
      "420 0.0006394648 [0.9835825] [1.1592722]\n",
      "440 0.0005584504 [0.9846577] [1.1553904]\n",
      "460 0.00048769647 [0.9856625] [1.1517628]\n",
      "480 0.00042591445 [0.9866015] [1.1483729]\n",
      "500 0.00037195202 [0.987479] [1.145205]\n",
      "520 0.0003248312 [0.98829895] [1.1422446]\n",
      "540 0.0002836779 [0.98906523] [1.1394781]\n",
      "560 0.00024773754 [0.98978126] [1.1368927]\n",
      "580 0.00021635168 [0.99045056] [1.1344765]\n",
      "600 0.00018894405 [0.99107593] [1.1322186]\n",
      "620 0.00016500465 [0.99166036] [1.1301086]\n",
      "640 0.00014410076 [0.9922065] [1.1281369]\n",
      "660 0.00012584473 [0.99271697] [1.1262941]\n",
      "680 0.00010990121 [0.99319386] [1.1245722]\n",
      "700 9.5976975e-05 [0.9936396] [1.1229628]\n",
      "720 8.381858e-05 [0.99405617] [1.121459]\n",
      "740 7.3201656e-05 [0.9944453] [1.120054]\n",
      "760 6.3928106e-05 [0.9948091] [1.1187407]\n",
      "780 5.5827404e-05 [0.99514914] [1.1175132]\n",
      "800 4.8754904e-05 [0.9954668] [1.1163661]\n",
      "820 4.2576547e-05 [0.99576366] [1.1152943]\n",
      "840 3.718238e-05 [0.9960411] [1.1142926]\n",
      "860 3.2470423e-05 [0.99630046] [1.1133565]\n",
      "880 2.8357947e-05 [0.99654275] [1.1124817]\n",
      "900 2.4765137e-05 [0.9967692] [1.1116643]\n",
      "920 2.1628086e-05 [0.9969807] [1.1109005]\n",
      "940 1.8887044e-05 [0.9971785] [1.1101865]\n",
      "960 1.6494794e-05 [0.9973633] [1.1095192]\n",
      "980 1.4405358e-05 [0.99753594] [1.1088959]\n",
      "1000 1.2579816e-05 [0.99769735] [1.1083133]\n",
      "1020 1.0986116e-05 [0.99784815] [1.1077688]\n",
      "1040 9.59357e-06 [0.99798906] [1.10726]\n",
      "1060 8.378503e-06 [0.9981207] [1.1067846]\n",
      "1080 7.3174488e-06 [0.9982438] [1.1063403]\n",
      "1100 6.3901607e-06 [0.99835885] [1.1059251]\n",
      "1120 5.5807345e-06 [0.99846625] [1.105537]\n",
      "1140 4.8735774e-06 [0.9985667] [1.1051745]\n",
      "1160 4.256153e-06 [0.99866056] [1.1048356]\n",
      "1180 3.7173581e-06 [0.99874824] [1.104519]\n",
      "1200 3.2463272e-06 [0.99883026] [1.1042231]\n",
      "1220 2.8350069e-06 [0.9989068] [1.1039466]\n",
      "1240 2.4760616e-06 [0.99897844] [1.1036881]\n",
      "1260 2.1623757e-06 [0.99904525] [1.1034467]\n",
      "1280 1.8884397e-06 [0.99910784] [1.1032209]\n",
      "1300 1.6492637e-06 [0.9991662] [1.1030099]\n",
      "1320 1.4401669e-06 [0.99922085] [1.1028129]\n",
      "1340 1.2578497e-06 [0.99927187] [1.1026286]\n",
      "1360 1.0983407e-06 [0.9993196] [1.1024563]\n",
      "1380 9.593933e-07 [0.99936414] [1.1022955]\n",
      "1400 8.3783686e-07 [0.9994058] [1.1021452]\n",
      "1420 7.316895e-07 [0.99944466] [1.1020048]\n",
      "1440 6.388906e-07 [0.9994811] [1.1018734]\n",
      "1460 5.580248e-07 [0.99951506] [1.1017507]\n",
      "1480 4.8734694e-07 [0.99954677] [1.1016362]\n",
      "1500 4.256317e-07 [0.9995764] [1.1015291]\n",
      "1520 3.7182653e-07 [0.99960417] [1.101429]\n",
      "1540 3.2460994e-07 [0.99963003] [1.1013354]\n",
      "1560 2.8350925e-07 [0.99965435] [1.1012479]\n",
      "1580 2.4763276e-07 [0.99967694] [1.1011662]\n",
      "1600 2.1636819e-07 [0.9996981] [1.10109]\n",
      "1620 1.8889057e-07 [0.9997178] [1.1010185]\n",
      "1640 1.6495406e-07 [0.99973625] [1.1009519]\n",
      "1660 1.4405514e-07 [0.9997536] [1.1008896]\n",
      "1680 1.2579919e-07 [0.9997697] [1.1008313]\n",
      "1700 1.0986437e-07 [0.99978477] [1.1007769]\n",
      "1720 9.594769e-08 [0.99979883] [1.100726]\n",
      "1740 8.3849045e-08 [0.99981207] [1.1006786]\n",
      "1760 7.3241516e-08 [0.9998243] [1.1006342]\n",
      "1780 6.3947084e-08 [0.99983585] [1.1005926]\n",
      "1800 5.585057e-08 [0.9998466] [1.1005538]\n",
      "1820 4.8779395e-08 [0.99985653] [1.1005175]\n",
      "1840 4.263393e-08 [0.999866] [1.1004838]\n",
      "1860 3.721076e-08 [0.99987465] [1.1004522]\n",
      "1880 3.2537308e-08 [0.99988294] [1.1004227]\n",
      "1900 2.8412263e-08 [0.9998905] [1.1003951]\n",
      "1920 2.4802933e-08 [0.99989766] [1.1003691]\n",
      "1940 2.17001e-08 [0.99990433] [1.1003453]\n",
      "1960 1.8974799e-08 [0.99991053] [1.1003228]\n",
      "1980 1.6551985e-08 [0.9999165] [1.1003014]\n",
      "2000 1.45046215e-08 [0.9999218] [1.1002821]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# X and Y data\n",
    "#x_train = [1, 2, 3, 4, 5]\n",
    "#y_train = [2.1, 3.1, 4.1, 5.1, 6.1]\n",
    "\n",
    "# Now we can use X and Y i place of x_data and y_data\n",
    "# # placegolders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis Wx + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)  # cost minimize 하는 node(이름: train) \n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph 필수!!\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = \\\n",
    "        sess.run([cost, W, b, train],\n",
    "                feed_dict={X: [1, 2, 3, 4, 5], \n",
    "                           Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
