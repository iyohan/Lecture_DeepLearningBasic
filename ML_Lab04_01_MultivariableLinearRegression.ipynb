{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariable Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hypothesis  \n",
    "H(x1, x2, x3) = x1w1 + x2w2 + x3w3  \n",
    "X * W = Y  \n",
    "[5, 3] X [3, 1] = [5, 1]  \n",
    "  \n",
    "아래 코드는 without matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  53779.7 \n",
      "Prediction:\n",
      "  [-55.121677 -61.94749  -63.156353 -70.65777  -44.506466]\n",
      "100 Cost:  1.633775 \n",
      "Prediction:\n",
      "  [150.68306 185.34079 180.53908 194.7194  144.09473]\n",
      "200 Cost:  1.5766627 \n",
      "Prediction:\n",
      "  [150.72086 185.31459 180.55026 194.73065 144.0577 ]\n",
      "300 Cost:  1.5224245 \n",
      "Prediction:\n",
      "  [150.7576  185.28908 180.5611  194.74167 144.02158]\n",
      "400 Cost:  1.4709707 \n",
      "Prediction:\n",
      "  [150.7933  185.26428 180.57164 194.75243 143.98637]\n",
      "500 Cost:  1.4221108 \n",
      "Prediction:\n",
      "  [150.82803 185.24016 180.58186 194.76295 143.95206]\n",
      "600 Cost:  1.3757327 \n",
      "Prediction:\n",
      "  [150.8618  185.21669 180.5918  194.77327 143.91862]\n",
      "700 Cost:  1.3317236 \n",
      "Prediction:\n",
      "  [150.8946  185.19385 180.60144 194.78337 143.88606]\n",
      "800 Cost:  1.2899252 \n",
      "Prediction:\n",
      "  [150.92653 185.17168 180.61082 194.79327 143.85432]\n",
      "900 Cost:  1.2502286 \n",
      "Prediction:\n",
      "  [150.95757 185.15009 180.61993 194.80298 143.8234 ]\n",
      "1000 Cost:  1.2125227 \n",
      "Prediction:\n",
      "  [150.98772 185.1291  180.62877 194.81245 143.79321]\n",
      "1100 Cost:  1.1767062 \n",
      "Prediction:\n",
      "  [151.01706 185.10867 180.63736 194.82176 143.76382]\n",
      "1200 Cost:  1.1426995 \n",
      "Prediction:\n",
      "  [151.04555 185.08885 180.64569 194.83086 143.73517]\n",
      "1300 Cost:  1.110375 \n",
      "Prediction:\n",
      "  [151.07327 185.06953 180.6538  194.83981 143.70726]\n",
      "1400 Cost:  1.0796698 \n",
      "Prediction:\n",
      "  [151.10019 185.05075 180.66164 194.84856 143.68004]\n",
      "1500 Cost:  1.0504916 \n",
      "Prediction:\n",
      "  [151.12636 185.03249 180.66925 194.85712 143.6535 ]\n",
      "1600 Cost:  1.0227604 \n",
      "Prediction:\n",
      "  [151.15181 185.01474 180.67667 194.86551 143.62764]\n",
      "1700 Cost:  0.9963646 \n",
      "Prediction:\n",
      "  [151.17653 184.99748 180.68382 194.87376 143.6024 ]\n",
      "1800 Cost:  0.97130233 \n",
      "Prediction:\n",
      "  [151.20058 184.9807  180.69083 194.88185 143.57784]\n",
      "1900 Cost:  0.9474629 \n",
      "Prediction:\n",
      "  [151.22394 184.9644  180.69759 194.88977 143.55388]\n",
      "2000 Cost:  0.9247697 \n",
      "Prediction:\n",
      "  [151.24664 184.94852 180.70415 194.89755 143.5305 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "y_data = [152., 185., 180., 196, 142]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n \", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  90610.3 \n",
      "Prediction:\n",
      "  [[-119.59638]\n",
      " [-133.61946]\n",
      " [-137.06554]\n",
      " [-149.06975]\n",
      " [ -99.17397]]\n",
      "100 Cost:  7.7013373 \n",
      "Prediction:\n",
      "  [[147.59175]\n",
      " [187.31554]\n",
      " [179.26399]\n",
      " [195.3926 ]\n",
      " [145.57794]]\n",
      "200 Cost:  7.302008 \n",
      "Prediction:\n",
      "  [[147.69759]\n",
      " [187.24301]\n",
      " [179.29646]\n",
      " [195.41573]\n",
      " [145.48308]]\n",
      "300 Cost:  6.923726 \n",
      "Prediction:\n",
      "  [[147.8006 ]\n",
      " [187.17242]\n",
      " [179.32806]\n",
      " [195.43825]\n",
      " [145.39075]]\n",
      "400 Cost:  6.565451 \n",
      "Prediction:\n",
      "  [[147.90086]\n",
      " [187.10374]\n",
      " [179.35884]\n",
      " [195.46014]\n",
      " [145.30092]]\n",
      "500 Cost:  6.226003 \n",
      "Prediction:\n",
      "  [[147.99846]\n",
      " [187.03687]\n",
      " [179.3888 ]\n",
      " [195.48145]\n",
      " [145.21347]]\n",
      "600 Cost:  5.9045134 \n",
      "Prediction:\n",
      "  [[148.09343]\n",
      " [186.97179]\n",
      " [179.41792]\n",
      " [195.5022 ]\n",
      " [145.12837]]\n",
      "700 Cost:  5.5999455 \n",
      "Prediction:\n",
      "  [[148.18587]\n",
      " [186.90843]\n",
      " [179.44629]\n",
      " [195.52235]\n",
      " [145.04553]]\n",
      "800 Cost:  5.31145 \n",
      "Prediction:\n",
      "  [[148.27586]\n",
      " [186.8468 ]\n",
      " [179.4739 ]\n",
      " [195.54199]\n",
      " [144.96494]]\n",
      "900 Cost:  5.038213 \n",
      "Prediction:\n",
      "  [[148.36343]\n",
      " [186.7868 ]\n",
      " [179.5008 ]\n",
      " [195.56107]\n",
      " [144.8865 ]]\n",
      "1000 Cost:  4.7793612 \n",
      "Prediction:\n",
      "  [[148.44867]\n",
      " [186.7284 ]\n",
      " [179.52695]\n",
      " [195.57964]\n",
      " [144.81017]]\n",
      "1100 Cost:  4.5341706 \n",
      "Prediction:\n",
      "  [[148.53163]\n",
      " [186.67155]\n",
      " [179.5524 ]\n",
      " [195.5977 ]\n",
      " [144.73587]]\n",
      "1200 Cost:  4.3018737 \n",
      "Prediction:\n",
      "  [[148.61241]\n",
      " [186.61624]\n",
      " [179.57721]\n",
      " [195.6153 ]\n",
      " [144.66357]]\n",
      "1300 Cost:  4.081869 \n",
      "Prediction:\n",
      "  [[148.691  ]\n",
      " [186.5624 ]\n",
      " [179.60133]\n",
      " [195.6324 ]\n",
      " [144.5932 ]]\n",
      "1400 Cost:  3.8734658 \n",
      "Prediction:\n",
      "  [[148.76749]\n",
      " [186.50998]\n",
      " [179.62482]\n",
      " [195.64903]\n",
      " [144.52472]]\n",
      "1500 Cost:  3.6760688 \n",
      "Prediction:\n",
      "  [[148.84193]\n",
      " [186.45895]\n",
      " [179.64766]\n",
      " [195.66519]\n",
      " [144.45808]]\n",
      "1600 Cost:  3.4890473 \n",
      "Prediction:\n",
      "  [[148.91443]\n",
      " [186.40932]\n",
      " [179.66992]\n",
      " [195.68095]\n",
      " [144.39323]]\n",
      "1700 Cost:  3.3119385 \n",
      "Prediction:\n",
      "  [[148.98495]\n",
      " [186.36101]\n",
      " [179.69157]\n",
      " [195.69627]\n",
      " [144.33012]]\n",
      "1800 Cost:  3.1441429 \n",
      "Prediction:\n",
      "  [[149.05362]\n",
      " [186.31398]\n",
      " [179.71266]\n",
      " [195.71118]\n",
      " [144.2687 ]]\n",
      "1900 Cost:  2.9852014 \n",
      "Prediction:\n",
      "  [[149.12044]\n",
      " [186.2682 ]\n",
      " [179.73318]\n",
      " [195.72568]\n",
      " [144.20892]]\n",
      "2000 Cost:  2.8346412 \n",
      "Prediction:\n",
      "  [[149.18549]\n",
      " [186.22365]\n",
      " [179.75316]\n",
      " [195.73978]\n",
      " [144.15076]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[73., 80., 75.], [93., 88., 93.], [89., 91., 90.],\n",
    "         [96., 98., 100.], [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n \", hy_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
